
If you are writing multithreaded applications, you have to be sensitive to the sequencing of operations. If your threads read and write shared data, this can be a problem. There are many ways to avoid this problem, such as never actually sharing data between threads. However, if you can’t avoid sharing data, you must provide for synchronization so that only one thread at a time can change the data.

Scalars such as Booleans and integers can often be synchronized properly with atomic operations, as described earlier; however, when your data is more complex and you need to use that data from multiple threads, you can provide explicit synchronization.

The Standard Library has support for mutual exclusion in the form of mutex and lock classes. These can be used to implement synchronization between threads and are discussed in the following sections.

\mySubsubsection{27.4.1.}{Mutex Classes}

Mutex stands for mutual exclusion. The basic mechanism of using a mutex is as follows:

\begin{itemize}
\item
A thread that wants to access (read or write) memory shared with other threads tries to lock the mutex object. If another thread is currently holding this lock, the new thread that wants to gain access blocks until the lock is released or until a timeout interval expires.

\item
Once the thread has obtained the lock, it is free to use the shared memory. Of course, this assumes that all threads that want to use the shared data participate in the mutexlocking scheme.

\item
After the thread is finished reading/writing to the shared memory, it releases its lock to give some other thread an opportunity to obtain a lock on the mutex. If two or more threads are waiting on the lock, there are no guarantees as to which thread will be granted the lock and thus allowed to proceed.
\end{itemize}

The C++ Standard Library provides non-timed and timed mutex classes, both in a recursive and non-recursive flavor. Before we discuss all these options, let’s first have a look at a concept called a spinlock.

\mySamllsection{Spinlock}

A spinlock is a synchronization mechanism where a thread uses a busy loop (spinning) to try to acquire a lock, performs its work, and releases the lock. While spinning, the thread remains active but is not doing any useful work. A mutex, on the other hand, might block the thread if the lock cannot be acquired immediately. Blocking a thread is an expensive operation that is avoided with a spinlock. Spinlocks can be useful in situations where you know the lock is going to be held for only a short time. Spinlocks can be implemented entirely in your own code. As the following code snippet demonstrates, a spinlock can be implemented using a single atomic type: atomic\_flag. The spinlock-related code is highlighted.

\begin{cpp}
static constexpr unsigned NumberOfThreads { 50 };
static constexpr unsigned LoopsPerThread { 100 };
void dowork(unsigned threadNumber, vector<unsigned>& data, atomic_flag& spinlock)
{
    for (unsigned i { 0 }; i < LoopsPerThread; ++i) {
        while (spinlock.test_and_set()) { } // Spins until lock is acquired.
        // Safe to handle shared data...
        data.push_back(threadNumber);
        spinlock.clear(); // Releases the acquired lock.
    }
}

int main()
{
    vector<unsigned> data;
    atomic_flag dataSpinlock;
    vector<jthread> threads;
    for (unsigned i { 0 }; i < NumberOfThreads; ++i) {
        threads.emplace_back(dowork, i, ref(data), ref(dataSpinlock));
    }
    for (auto& t : threads) { t.join(); }
    println("data contains {} elements, expected {}.", data.size(),
        NumberOfThreads * LoopsPerThread);
}
\end{cpp}

In this code, each thread tries to acquire a lock by repeatedly calling test\_and\_set() on an atomic\_flag until it succeeds. This is the busy loop.

\begin{myWarning}{WARNING}
As spinlocks use a busy waiting loop, they should be an option only when you know for sure that threads will lock the spinlock only for brief moments of time.
\end{myWarning}

Let’s now look at which mutex classes the Standard Library provides.

\mySamllsection{Non-timed Mutex Classes}

The Standard Library has three non-timed mutex classes: std::mutex, recursive\_mutex, and shared\_mutex. The first two classes are defined in <mutex>, and the last one in <shared\_mutex>. Each mutex supports the following member functions:

\begin{itemize}
\item
lock(): The calling thread tries to obtain the lock and blocks until the lock has been acquired. It blocks indefinitely. If there is a desire to limit the amount of time the thread blocks, you should use a timed mutex, discussed in the next section.

\item
try\_lock(): The calling thread tries to obtain the lock. If the lock is currently held by another thread, the call returns immediately. If the lock has been obtained, try\_lock() returns true; otherwise, it returns false.

\item
unlock(): The calling thread releases the lock it currently holds, making it available for another thread.
\end{itemize}

std::mutex is a standard mutual exclusion class with exclusive ownership semantics. There can be only one thread owning the mutex. If another thread wants to obtain ownership of this mutex, it either blocks when using lock() or fails when using try\_lock(). A thread already having ownership of a mutex is not allowed to call lock() or try\_lock() again on that mutex. This might lead to a deadlock!

std::recursive\_mutex behaves almost identically to mutex, except that a thread already having ownership of a recursive mutex is allowed to call lock() or try\_lock() again on the same recursive mutex. The calling thread should call the unlock() member function as many times as it obtained a lock on the recursive mutex.

The shared\_mutex class supports the concept of shared lock ownership, also known as readerswriter lock. A thread can get either exclusive ownership or shared ownership of the lock. Exclusive ownership, also known as a write lock, can be acquired only when there are no other threads having exclusive or shared ownership. Shared ownership, also known as a read lock, can be acquired if there is no other thread having exclusive ownership, even if other threads have already acquired their own shared ownership. The shared\_mutex class supports lock(), try\_lock(), and unlock(). These member functions acquire and release exclusive locks. Additionally, they have the following shared ownership-related member functions: lock\_shared(), try\_lock\_shared(), and unlock\_shared(). These work similarly to the other set of member functions but try to acquire or release shared ownership.

A thread already having a lock on a shared\_mutex is not allowed to try to acquire a second lock on that mutex. This might lead to a deadlock!

Before examples on how to use these mutex classes can be given, a couple of other topics need to be discussed first. Hence, examples are discussed in the section “Examples Using Mutexes” later in this chapter.

\begin{myWarning}{WARNING}
Do not manually call the previously discussed lock and unlock member functions on any of the mutex classes discussed in this section and the next one. Mutex locks are resources, and, like all resources, they should almost exclusively be acquired using the Resource Acquisition Is Initialization (RAII) paradigm; see Chapter 32, “Incorporating Design Techniques and Frameworks.” The C++ Standard Library provides a number of RAII lock classes, which are discussed in the “Locks” section later in this chapter. Using them is critical to avoid deadlocks. They automatically unlock a mutex when a lock object goes out of scope, so you don’t need to remember to manually call unlock() at the right time.
\end{myWarning}

\mySamllsection{Timed Mutex Classes}

When calling lock() on any of the previously discussed mutex classes, the call blocks until the lock can be obtained. On the other hand, calling try\_lock() on those mutex classes tries to acquire a lock but returns immediately if not successful. There are also timed mutex classes that can try to obtain a lock but give up after a certain amount of time.

The Standard Library provides three timed mutex classes: std::timed\_mutex, recursive\_timed\_mutex, and shared\_timed\_mutex. The first two classes are defined in <mutex>, and the last one in <shared\_mutex>. They all support the lock(), try\_lock(), and unlock() member functions; and shared\_timed\_mutex also supports lock\_shared(), try\_lock\_shared(), and unlock\_shared(). All these behave the same as described in the previous section. Additionally, they support the following member functions:

\begin{itemize}
\item
try\_lock\_for(rel\_time): The calling thread tries to obtain the lock for a certain relative time. If the lock could not be obtained after the given timeout, the call fails and returns false. If the lock could be obtained within the timeout, the call succeeds and returns true. The timeout is specified as an std::chrono::duration; see Chapter 22.

\item
try\_lock\_until(abs\_time): The calling thread tries to obtain the lock until the system time equals or exceeds the specified absolute time. If the lock could be obtained before this time, the call returns true. If the system time passes the given absolute time, the function stops trying to obtain the lock and returns false. The absolute time is specified as an std::chrono::time\_point; see Chapter 22.
\end{itemize}

A shared\_timed\_mutex also supports try\_lock\_shared\_for() and try\_lock\_shared\_until().

A thread already having ownership of a timed\_mutex or a shared\_timed\_mutex is not allowed to acquire the lock a second time on that mutex. This might lead to a deadlock!

A recursive\_timed\_mutex allows a thread to acquire a lock multiple times, just as with recursive\_mutex.

\mySubsubsection{27.4.2.}{Locks}

A lock class is an RAII class that makes it easier to correctly obtain and release a lock on a mutex; the destructor of the lock class automatically releases the associated mutex. The C++ standard defines four types of locks: std::lock\_guard, unique\_lock, shared\_lock, and scoped\_lock.

\mySamllsection{lock\_guard}

lock\_guard, defined in <mutex>, is a simple lock with two constructors:

\begin{cpp}
explicit lock_guard(mutex_type& m);
\end{cpp}

Constructor accepting a reference to a mutex. Tries to obtain a lock on the mutex and blocks until the lock is obtained.

\begin{cpp}
lock_guard(mutex_type& m, adopt_lock_t);
\end{cpp}

Constructor accepting a reference to a mutex and a second argument equal to std::adopt\_lock, which is a global constant of the tag type std::adopt\_lock\_t, which is provided by the Standard Library for exactly this purpose. The lock assumes that the calling thread has already called lock() on the referenced mutex. The lock\_guard “adopts” the mutex and automatically releases the mutex when the lock\_guard is destroyed.


\mySamllsection{unique\_lock}

std::unique\_lock, defined in <mutex>, is a more sophisticated lock that allows you to defer lock acquisition until later in the execution, long after the declaration. You can use the owns\_lock() member function or the unique\_lock’s bool conversion operator to see if the lock has been acquired. An example of using this conversion operator is given later in this chapter in the section “Using Timed Locks.” unique\_lock has several constructors:

\begin{cpp}
explicit unique_lock(mutex_type& m);
\end{cpp}

Accepts a reference to a mutex. Tries to obtain a lock on the mutex and blocks until the lock is obtained.

\begin{cpp}
unique_lock(mutex_type& m, defer_lock_t) noexcept;
\end{cpp}

Accepts a reference to a mutex and an instance of std::defer\_lock\_t, for example std::defer\_lock. The unique\_lock stores the reference to the mutex, but does not immediately try to obtain a lock. A lock can be obtained later.

\begin{cpp}
unique_lock(mutex_type& m, try_to_lock_t);
\end{cpp}

Accepts a reference to a mutex and an instance of std::try\_to\_lock\_t, for example std::try\_to\_lock. The lock tries to obtain a lock to the referenced mutex, but if it fails, it does not block, in which case, a lock can be obtained later.

\begin{cpp}
unique_lock(mutex_type& m, adopt_lock_t);
\end{cpp}

Accepts a reference to a mutex and an instance of std::adopt\_lock\_t, for example std::adopt\_lock. The lock assumes that the calling thread has already called lock() on the referenced mutex. The lock “adopts” the mutex and automatically releases the mutex when the lock is destroyed.

\begin{cpp}
unique_lock(mutex_type& m, const chrono::time_point<Clock, Duration>& abs_time);
\end{cpp}

Accepts a reference to a mutex and an absolute time. Tries to obtain a lock until the system time passes the given absolute time.

\begin{cpp}
unique_lock(mutex_type& m, const chrono::duration<Rep, Period>& rel_time);
\end{cpp}

Accepts a reference to a mutex and a relative time. Tries to get a lock on the mutex with the given relative timeout.

The unique\_lock class also has the member functions lock(), try\_lock(), try\_lock\_for(), try\_lock\_until(), and unlock(), which behave as explained in the section “Timed Mutex Classes,” earlier in this chapter.

\mySamllsection{shared\_lock}

The shared\_lock class, defined in <shared\_mutex>, has the same type of constructors and the same member functions as unique\_lock. The difference is that shared\_lock calls the shared ownership-related member functions on the underlying shared mutex. Thus, the member functions of shared\_lock are called lock(), try\_lock(), and so on, but on the underlying shared mutex they call lock\_shared(), try\_lock\_shared(), and so on. This is done to give shared\_lock the same interface as unique\_lock, so it can be used as a drop-in replacement for unique\_lock, but acquires a shared lock instead of an exclusive lock.

\mySamllsection{Acquiring Multiple Locks at Once}

C++ has two generic lock functions that you can use to obtain locks on multiple mutex objects at once without the risk of creating deadlocks. Both functions are defined in the std namespace, and both are variadic function templates, as discussed in Chapter 26.

The first function, lock(), locks all the given mutex objects in an unspecified order without the risk of deadlocks. If one of the mutex lock calls throws an exception, unlock() is called on all locks that have already been obtained. Its prototype is as follows:

\begin{cpp}
template <class L1, class L2, class... Ln> void lock(L1&, L2&, Ln&...);
\end{cpp}

try\_lock() has a similar prototype, but it tries to obtain a lock on all the given mutex objects by calling try\_lock() on each of them in sequence. It returns -1 if all calls to try\_lock() succeed. If any try\_lock() fails, unlock() is called on all locks that have already been obtained, and the return value is the zero-based index of the mutex argument on which try\_lock() failed.

The following example demonstrates how to use the generic lock() function. The process() function first creates two locks, one for each mutex, and gives an instance of std::defer\_lock\_t as a second argument to tell unique\_lock not to acquire the lock during construction. The call to std::lock() then acquires both locks without the risk of deadlocks.

\begin{cpp}
mutex mut1;
mutex mut2;

void process()
{
    unique_lock lock1 { mut1, defer_lock };
    unique_lock lock2 { mut2, defer_lock };
    lock(lock1, lock2);
    // Locks acquired.
} // Locks automatically released.
\end{cpp}

\mySamllsection{scoped\_lock}

std::scoped\_lock, defined in <mutex>, is similar to lock\_guard, except that it accepts a variable number of mutexes. This greatly simplifies acquiring multiple locks. For instance, the example with the process() function from the previous section can be written using a scoped\_lock as follows:

\begin{cpp}
mutex m1;
mutex m2;

void process()
{
    scoped_lock locks { m1, m2 }; // Uses class template argument deduction, CTAD.
    // Locks acquired.
} // Locks automatically released.
\end{cpp}

\begin{myNotic}{NOTE}
scoped\_lock simplifies acquiring multiple locks, because you don’t need to worry about acquiring them in the right order.
\end{myNotic}

scoped\_lock is a variadic class template capable of locking an arbitrary number of mutexes. Suppose that you have an std::array with mutexes and a need to acquire a lock on all those mutexes at once. To make this easy, you can write a helper variadic function template in combination with using std::index\_sequence and make\_index\_sequence, both of which are introduced in Chapter 26. Here’s an example:

\begin{cpp}
// Helper function to create the actual scoped_lock instance.
template <size_t N, size_t... Is>
auto make_scoped_lock(array<mutex, N>& mutexes, index_sequence<Is...>)
{
    return scoped_lock { mutexes[Is]... };
}

// Helper function to make it easy to use.
template <size_t N>
auto make_scoped_lock(array<mutex, N>& mutexes)
{
    return make_scoped_lock(mutexes, make_index_sequence<N>{});
}

int main()
{
    array<std::mutex, 4> mutexes;
    auto lockAll { make_scoped_lock(mutexes) };
}
\end{cpp}

\mySubsubsection{27.4.3.}{std::call\_once}

You can use std::call\_once() in combination with std::once\_flag to make sure a certain function or member function is called exactly one time, no matter how many threads try to call call\_once() with the same once\_flag. Only one call\_once() invocation actually calls the given function. If the given function does not throw any exceptions, then this invocation is called the effective call\_once() invocation. If the given function does throw an exception, the exception is propagated back to the caller, and another caller is selected to execute the function. The effective invocation on a specific once\_flag instance finishes before all other call\_once() invocations on the same once\_flag. Other threads calling call\_once() on the same once\_flag block until the effective call is finished. Figure 27.4 illustrates this with three threads. Thread 1 performs the effective call\_once() invocation, thread 2 blocks until the effective invocation is finished, and thread 3 doesn’t block because the effective invocation from thread 1 has already finished.

\myGraphic{0.7}{content/part4/chapter27/images/4.png}{FIGURE 27.4}

The following example demonstrates the use of call\_once(). The example launches three threads running processingFunction() that use some shared resources. These shared resources are initialized by calling initializeSharedResources() once. To accomplish this, each thread calls call\_once() with a global once\_flag. The result is that only one thread effectively executes initializeSharedResources(), and exactly one time. While this call\_once() call is in progress, other threads block until initializeSharedResources() returns.

\begin{cpp}
once_flag g_onceFlag;
void initializeSharedResources()
{
    // ... Initialize shared resources to be used by multiple threads.
    println("Shared resources initialized.");
}

void processingFunction()
{
    // Make sure the shared resources are initialized.
    call_once(g_onceFlag, initializeSharedResources);
    // ... Do some work, including using the shared resources
    println("Processing");
}

int main()
{
    // Launch 3 threads.
    vector<jthread> threads { 3 };
    for (auto& t : threads) {
        t = jthread { processingFunction };
    }
    // No need to manually call join(), as we are using jthread.
}
\end{cpp}

The output of this code is as follows:

\begin{shell}
Shared resources initialized.
Processing
Processing
Processing
\end{shell}

Of course, in this example, you could call initializeSharedResources() once in the beginning of the main() function before the threads are launched; however, that wouldn’t demonstrate the use of call\_once().

\mySubsubsection{27.4.4.}{Examples Using Mutexes}

The following sections give a couple of examples on how to use mutexes to synchronize multiple threads.

\mySamllsection{Thread-Safe Writing to Streams}

Earlier in this chapter, in the “Threads” section, there is an example with a class called Counter. That example mentions that C++ streams, such as cout, are data-race-free by default, but that the output from multiple threads can be interleaved. Here are two solutions to solve this interleaving issue:

\begin{itemize}
\item
Use a synchronized stream.

\item
Use a mutex to make sure that only one thread at a time is reading/writing to the stream object.
\end{itemize}

\mySamllsection{Synchronized Streams}

<syncstream> defines std::basic\_osyncstream with predefined type aliases osyncstream and wosyncstream for char and wchar\_t streams, respectively. The O in these class names stands for output. These classes guarantee that all output done through them will appear in the final output stream the moment the synchronized stream is destroyed. It guarantees that the output cannot be interleaved by other output from other threads, as long as those threads are also using their own osyncstream objects. As far as thread-safety is concerned, the relationship between osyncstream and ostream is exactly analogous to the relationship between atomic\_ref<int> and int.

The function call operator of the earlier Counter class can be implemented as follows using an osyncstream to prevent interleaved output:

\begin{cpp}
class Counter
{
    public:
        explicit Counter(int id, int numIterations)
            : m_id { id }, m_numIterations { numIterations } { }

        void operator()() const
        {
            for (int i { 0 }; i < m_numIterations; ++i) {
                osyncstream syncedCout { cout };
                syncedCout << format("Counter {} has value {}", m_id, i);
                syncedCout << endl;
                // Upon destruction, syncedCout atomically flushes
                // its contents into cout.
            }
        }
    private:
        int m_id { 0 };
        int m_numIterations { 0 };
};
\end{cpp}

\mySamllsection{Using Mutexes}

If you cannot use a synchronized stream, you can use a mutex as demonstrated in the following code snippet to synchronize all accesses to cout in the Counter class. For this, a static mutex data member is added. It should be static, because all instances of the class should use the same mutex instance. lock\_guard is used to obtain a lock on the mutex before writing to cout.

\begin{cpp}
class Counter
{
    public:
        explicit Counter(int id, int numIterations)
            : m_id { id }, m_numIterations { numIterations } { }

        void operator()() const
        {
            for (int i { 0 }; i < m_numIterations; ++i) {
                lock_guard lock { ms_mutex };
                cout << format("Counter {} has value {}", m_id, i) << endl;
            }
        }
    private:
        int m_id { 0 };
        int m_numIterations { 0 };
        inline static mutex ms_mutex;
};
\end{cpp}

This code creates a lock\_guard instance on each iteration of the for loop. It is recommended to limit the time a lock is held as much as possible; otherwise, you are blocking other threads for too long.

For example, if the lock\_guard instance was created once right before the for loop, then you would basically lose all multithreading in this code because one thread would hold a lock for the entire duration of its for loop, and all other threads would wait for this lock to be released.

\begin{myNotic}{NOTE}
Try to hold locks as short as possible. This means you should avoid using slow operations while holding a lock, such as printing messages to the console, reading data from files, accessing databases, performing long calculations, doing explicit sleeps, and so on.
\end{myNotic}

\mySamllsection{Using Timed Mutexes}

The following example demonstrates how to use a timed mutex. It is the same Counter class as before, but this time it uses a timed\_mutex in combination with a unique\_lock. A relative time of 200 milliseconds is given to the unique\_lock constructor, causing it to try to obtain a lock for 200 milliseconds. If the lock cannot be obtained within this timeout interval, the constructor returns. Afterward, you can check whether the lock has been acquired. You can do this with an if statement on the lock variable, because unique\_lock defines a bool conversion operator. The timeout is specified using the chrono library, discussed in Chapter 22.

\begin{cpp}
class Counter
{
    public:
        explicit Counter(int id, int numIterations)
            : m_id { id }, m_numIterations { numIterations } { }

        void operator()() const
        {
            for (int i { 0 }; i < m_numIterations; ++i) {
                unique_lock lock { ms_timedMutex, 200ms };
                if (lock) {
                    cout << format("Counter {} has value {}", m_id, i) << endl;
                } else {
                    // Lock not acquired in 200ms, skip output.
                }
            }
        }
    private:
        int m_id { 0 };
        int m_numIterations { 0 };
        inline static timed_mutex ms_timedMutex;
};
\end{cpp}


\mySamllsection{Double-Checked Locking}

The double-checked locking pattern is actually an anti-pattern, which you should avoid! It is shown here because you might come across it in existing code bases. The idea of the double-checked locking pattern is to try to avoid the use of mutexes. It’s a half-baked attempt at trying to write more efficient code than using a mutex. It can really go wrong when you try to make it faster than demonstrated in the upcoming example, for instance, by using relaxed atomics (not further discussed), using a regular bool instead of an atomic<bool>, and so on. The pattern becomes sensitive to data races, and it is hard to get right. The irony is that using call\_once() will usually be faster, and using a magic static (if applicable) will be even faster.

\begin{myNotic}{NOTE}
Function-local static variables are called magic statics or thread-safe statics. C++ guarantees that such local static variables are initialized in a threadsafe fashion, so you don’t need any manual thread synchronization. An example of using a magic static is given in Chapter 33, “Applying Design Patterns,” with the discussion of the singleton pattern.
\end{myNotic}

\begin{myWarning}{WARNING}
Avoid the double-checked locking pattern! Instead, use other mechanisms such as simple locks, atomic variables, call\_once(), magic statics, and so on.
\end{myWarning}

Double-checked locking could, for example, be used to make sure that resources are initialized exactly once. The following example shows how you can implement this. It is called the doublechecked locking pattern because it is checking the value of the g\_initialized variable twice, once before acquiring the lock and once right after acquiring the lock. The first g\_initialized check is used to prevent acquiring a lock when it is not needed. The second check is required to make sure that no other thread performed the initialization between the first g\_initialized check and acquiring the lock.

\begin{cpp}
void initializeSharedResources()
{
    // ... Initialize shared resources to be used by multiple threads.
    println("Shared resources initialized.");
}

atomic<bool> g_initialized { false };
mutex g_mutex;

void processingFunction()
{
    if (!g_initialized) {
        unique_lock lock { g_mutex };
        if (!g_initialized) {
            initializeSharedResources();
            g_initialized = true;
        }
    }
    print("1");
}

int main()
{
    vector<jthread> threads;
    for (int i { 0 }; i < 5; ++i) {
        threads.emplace_back(processingFunction);
    }
}
\end{cpp}

The output clearly shows that only one thread initializes the shared resources:

\begin{shell}
Shared resources initialized.
11111
\end{shell}


\begin{myNotic}{NOTE}
For this example, it’s recommended to use call\_once() as demonstrated earlier in this chapter, instead of double-checked locking!
\end{myNotic}





